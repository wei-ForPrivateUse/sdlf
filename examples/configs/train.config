# Training configurations need to be organized as a dict
#
# **********  example  ***********
# optimizer:
#     type: adam
#     amsgrad: false
#     weight_decay: 0.01
#     fixed_weight_decay: true
#
# lr_scheduler:
#     type: one_cycle
#     total_step:
#     lr_max:
#     moms: [0.95, 0.85]
#     div_factor: 10.0
#     pct_start: 0.4
#
# training:
#     eval_step_list:
#     save_step_list:
#     eval_fn:
#     eval_ext_args:
# ********************************
